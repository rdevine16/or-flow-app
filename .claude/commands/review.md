# /review â€” Pre-Implementation Review & Questions

You are about to review a feature spec before implementation begins. Your job is to be the senior engineer doing a design review â€” find the gaps, ambiguities, and assumptions the spec makes that could cause problems during implementation.

## Steps

### Step 1: Read the Feature Spec
Read `docs/active-feature.md` carefully. Understand the full scope.

### Step 2: Scan the Codebase
Based on what the spec describes, examine the relevant parts of the codebase:

- **Existing components**: Check `components/ui/` and `components/cases/` (or whatever the relevant domain folder is). What already exists that overlaps with what the spec wants to create? Are there patterns, utilities, or components that should be reused or extended rather than rebuilt?
- **Existing hooks & data patterns**: Check `lib/hooks/` â€” how does the app currently fetch data? What patterns exist (useSupabaseQuery, direct Supabase client calls, SWR, React Query)? The new hooks MUST match the existing pattern.
- **Database schema**: Check types, Supabase queries, or schema files to verify the spec's assumptions about table columns, relationships, and available data.
- **Existing page structure**: Look at the current implementation of the page being redesigned. What state management, routing, and layout patterns are in place?
- **Design tokens & styling**: Check for existing color constants, spacing patterns, component libraries (shadcn? custom?), and Tailwind conventions.
- **Similar pages**: Look at other pages in the app that have similar patterns (tables, filters, drawers, tabs) â€” the new page should be consistent with them.

### Step 3: Generate Questions

Organize your questions into these categories. Ask **only questions that would change implementation decisions.** Skip obvious things. Be specific â€” reference actual files and code you found.

**ðŸ” Existing Code & Patterns**
Questions about existing components, hooks, utilities, or patterns that the spec doesn't mention but that you found in the codebase. Things like:
- "I found `components/ui/Badge.tsx` â€” should the new StatusBadge extend this or replace it?"
- "The app uses `useSupabaseQuery` everywhere â€” should the new hooks follow this pattern?"
- "There's already a `CaseListView.tsx` â€” what happens to it?"

**ðŸ“Š Data & Schema**
Questions about database assumptions, missing columns, query feasibility:
- "The spec assumes `procedure_types.category` exists for icon mapping â€” I see [X] in the schema. Is this the right field?"
- "case_completion_stats doesn't have [column] â€” how should the financials tab handle this?"
- "The milestone progress calculation assumes all cases have milestones. What about cases created before milestone tracking was enabled?"

**ðŸŽ¨ Design & UX Decisions**
Questions about visual or interaction details the spec leaves ambiguous:
- "Should the drawer push the table content left or overlay on top?"
- "What happens when you click a row that's already open in the drawer â€” close it or stay open?"
- "The spec says 'procedure icons by category' â€” your procedure_types table has [these categories]. Which ones get unique icons?"

**âš™ï¸ Edge Cases & Error Handling**
Questions about scenarios the spec doesn't cover:
- "What happens if a surgeon has zero cases for a procedure type â€” no median available for projections?"
- "How should the bulk validation handle a case that fails validation (e.g., missing required milestones)?"
- "Should cancelled cases appear in any tab or be excluded entirely?"

**ðŸ”— Integration & Side Effects**
Questions about how this feature connects to other parts of the app:
- "Validating a case triggers `record_case_stats` â€” should the drawer show a loading state while stats recompute?"
- "The spec mentions linking surgeon name to their scorecard â€” what's the route? `/surgeons/[id]`? `/analytics/surgeons/[id]`?"
- "Does the 'New Case' button open the existing case creation form or is that changing too?"

### Step 4: Present Questions and STOP

Output all your questions organized by category. Use numbered questions so I can reference them in my answers (e.g., "For Q3, do X").

**End with:**
> Answer these questions and I'll incorporate your answers into the implementation plan when you run `/audit`.

Then **STOP**. Do not generate an implementation plan. Do not start coding. Do not create any files. Wait for answers.

### Step 5: Save Answers

When I provide answers, append them to `docs/active-feature.md` under a new section:

```markdown
## Review Q&A

> Generated by /review on [date]

### Existing Code & Patterns
**Q1:** [question]
**A1:** [my answer]

### Data & Schema
**Q2:** [question]
**A2:** [my answer]

[... etc]
```

Then say: "Answers saved. Run `/audit` to generate the implementation plan â€” it will incorporate these decisions."
